\section{Installation and Configuration}

\subsection{Complete list of packages}

\LB is currently distributed mainly in RPMs packages. It is available also in
binary form packed as .tar.gz. Recent attempts to multiplatform porting and
recent ETICS building system development promise a future possibility to
distribute the software in other distribution formats, e.g. DEB packages. 

In \LBold, the list of all LB packages was the following:

\begin{tabularx}{\textwidth}{>{\tt}lX}
glite-lb-common & common files \\ 
glite-lb-client & client library and CLI tools\\ 
glite-lb-client-interface & client library interface (header files) \\ 
glite-lb-logger & local-logger and inter-logger \\ 
glite-lb-proxy & proxy (restricted server used by WMS)\\ 
glite-lb-server & server \\ 
glite-lb-server-bones & multi-process server building library \\ 
glite-lb-utils & auxiliary utilities \\ 
glite-lb-ws-interface & web service interface  \\
glite-security-gsoap-plugin & GSS wrapper and GSS plugin for gSoap
\end{tabularx}

In \LBnew, the code has been restructured quite a lot, especially the dependencies were lightened,
and the new list of packages is now the following:

\begin{tabularx}{\textwidth}{>{\tt}lX}
glite-lb-doc & documentation \\ 
glite-lb-common & common files \\ 
glite-lb-client & client library and CLI tools\\ 
glite-lb-logger & local-logger and inter-logger \\
glite-lb-server & server, including merged proxy functionality \\
glite-lb-state-machine & state machine and LB plugin for Job Provenance \\ 
glite-lb-utils & auxiliary utilities \\
glite-lb-ws-interface & web service interface \\
\end{tabularx}

More detailed description together with the dependencies can be read directly from each package,
for example by issuing the command 
\begin{verbatim}
   rpm -qiR <package_name>
\end{verbatim}

Some of the LB packages depend also on other gLite packages, different 
due to the restructuring of \LBnew.
For \LBold they are:


\begin{tabularx}{\textwidth}{>{\tt}lX}
glite-wms-utils-jobid & gLite jobId management library \\
glite-jp-common & Job Provenance auxiliary library \\ 
\end{tabularx}

\noindent
And for \LBnew:

\begin{tabularx}{\textwidth}{>{\tt}lX}
glite-jobid-api-c & gLite jobId C API library \\ 
% pro beh LB neni triba
% glite-jp-common & JP common files \\ 
glite-lbjp-common-db & database access layer \\
glite-lbjp-common-maildir & persistent request spool management \\
glite-lbjp-common-server-bones & multi-process server building library \\
glite-lbjp-common-trio & extended printf implementation \\
glite-security-gss & GSS wrapper \\
glite-security-gsoap-plugin & GSS plugin for gSoap \\
\end{tabularx}

where all \verb'glite-lbjp-common-*' packages are common both to \LB and 
Job Provenance (\JP).


\subsection{\LB server}

\subsubsection{Hardware requirements}
\label{inst:hw_req}

Hardware requirements depend on performance and storage time requirements.
Disk space used by LB server consists of database space and working space 
for backup dumps and temporary files used by exports to Job Provenance and
R-GMA tables. Necessary database space can be calculated by multiplying 
job retention length (job purge timeout), job submission rate, and  
per-job space requirements (120\,KB per job is recommended for current common 
EGEE usage pattern; jobs can consume more than that with use of very long
JDL descriptions, user tags, or very high number of resubmissions).
For temporary files, approximately 10\,GB is sufficient for LB server setups
working normally, more can be needed when backlog forms in data export
to any external service. For example, typical setup processing 40\,000 jobs per 
day where all jobs are purged after 10 days needs about 58 gigabytes
($10 \cdot 40000 \cdot 120 \mbox{KB (per job)} + 10$) not accounting for operating 
system and system logs.

For smooth handling of 40\,000 jobs/day, this or better machine configuration 
is necessary:
\begin{itemize}
\item 1GB RAM
\item CPU equivalent of single Xeon/Opteron 1.5GHz
\item single 7200 rpm SATA disk.
\end{itemize}
In order to achieve higher performace, following changes are recommended:
\begin{itemize}
\item Faster disks. Disk access speed is crucial for LB server, couple of 15k rpm
SCSI or SAS disks (one for MySQL database data file, the second for DB logs, LB server's
working directories, and operating system files) or RAID with battery backed 
write-back cache is preferable.
\item More memory. Large RAM improves performance through memory caching,
relative speed gain is likely to be rougly proportional to memory/database size ratio.
To use 3\,GB or more efficiently, 64bit OS and MySQL server versions are recommended.
\item Faster or more processors. CPU requirements scale approximately linearly with
offered load.
\end{itemize}

\subsubsection{Standard installation}

Install and configure OS and basic services (certificates, CAs, time synchronization, software repositories) according to the \htmladdnormallink{https://twiki.cern.ch/twiki/bin/view/LCG/GenericInstallGuide320}{https://twiki.cern.ch/twiki/bin/view/LCG/GenericInstallGuide320}. Then glite-LB metapackage from appropriate gLite software repository should be installed.

YAIM configuration for \emph{glite-LB} node type 
(\texttt{/opt/glite/yaim/bin/yaim -c -s site-info.def -n glite-LB}) 
can be done then. Available parameters specific to LB server are:

%variable&meaning&default value &further details\\
\begin{itemize}
\item \texttt{MYSQL\_PASSWORD} -- root password of MySQL server (mandatory)
\item \texttt{GLITE\_WMS\_LCGMON\_FILE} -- pathname of file where job state
export data are written for use by lgcmon/R-GMA 
(default: \texttt{/var/glite/logging/status.log}
\item \texttt{GLITE\_LB\_EXPORT\_PURGE\_ARGS} -- purge timeouts (default: \texttt{--cleared 2d --aborted 15d --cancelled 15d --other 60d})
\item \texttt{GLITE\_LB\_EXPORT\_ENABLED} -- set to \texttt{true} for export to JP, installed glite-lb-client and glite-jp-client are needed (default: \texttt{false})
\item \texttt{GLITE\_LB\_EXPORT\_JPPS} -- Job Provenance Primary Storage where to export purged jobs, required if export to JP is enabled
\item \texttt{GLITE\_JP\_LOCATION} -- optional parameter for combining LB and JP subsystems on the different locations
\item \texttt{GLITE\_LB\_RTM\_ENABLED} -- enable settings for Real Time Monitor - indexes and additional access (default: false)
\item \texttt{GLITE\_LB\_RTM\_DN} -- DN using to get notifications from \LB server\\
(default: \texttt{heppc24.hep.ph.ic.ac.uk} machine certificate)
\item \texttt{GLITE\_LB\_SUPER\_USERS} -- additional super-users (default: empty)
\end{itemize}

In addition to those, YAIM LB module uses following parameters:
\texttt{INSTALL\_ROOT}, \texttt{GLITE\_LOCATION\_VAR}, \texttt{GLITE\_USER}, \texttt{GLITE\_HOME\_DIR},\texttt{SITE\_EMAIL}.

\subsubsection{Migration to a different OS version}
\label{inst:OSmigration}
Migration of a LB server to different machine is possible using
following simple procedure (just file copy of the MySQL database). We
tested the migration from SL4 32bit (mysql 4.1.22-2) to SL5 64bit
(mysql 5.0.45-7).

Steps:
\begin{itemize}
\item \emph{Prepare a new machine.} The new machine must get the same hostname 
 as the old machine had. It is a part of job ids stored in the database.
\item \emph{Move data.} Just stop the MySQL server and move
 \verb'/var/lib/mysql' data directory directly to the target machine.
\item \emph{(optional) Restore file contexts.} You may need to restore file 
 contexts in case of enabled SELinux. For example, commands on the target 
 machine:
 \begin{verbatim}
 service mysqld stop
 cd /var/lib
 tar xf /tmp/lb.tar
 restorecond -R mysql
 service mysqld start
 \end{verbatim}
\end{itemize}

\subsubsection{Migration of database to support transactions}
Started from version 1.4.3 of the \texttt{glite-lb-server}
package, the \LB server introduced optional use of database
transactions for \LB database updates in order to improve their
performace. This feature is switched on by default when underlying
MySQL database uses transactional InnoDB tables. For new
installations, YAIM configuration process will create transactional
database automatically. For existing LB server database the migration 
process is not automatically handled.

Note: If you want to add transaction when migrating to \LB 2.0 skip
this section and use \LB 2.0 migration procedure. The migration of
database to support transactions is included in \LB 2.0 migration procedure.

Steps:
\begin{itemize}
 \item \emph{Stop the server.} Stop both a \LB server and a MySQL
 server. Making a fresh backup copy of database is a good idea.
 \item \emph{Database conversion.} Use provided SQL script:
  \begin{quote}
   \begin{verbatim}
mysql -u lbserver lbserver20 \
        </opt/glite/etc/glite-lb-dbsetup-migrate2transactions.sql
   \end{verbatim}
  \end{quote}
 \item \emph{Start the servers.} MySQL and \LB. Check logs.
\end{itemize}


\subsubsection{Migration to \LB 2.0}
The migration process of existing \LB 1.x database to the \LB 2.0 is
not handled automatically. The database schema change is required due
to support of merged \LB server and proxy services using single
database, pointers to purged jobs (``zombies'') and other
improvements.

Warning: There are two types of \LB database based on the fact that
you can have a \LB server or \LB proxy. For more information about \LB
proxy please see \ref{inst:LBproxy}.

Steps:
\begin{itemize}
 \item \emph{Stop the server and upgrade to \LB 2.0.} Stop both a \LB
 server and a MySQL server. Making a fresh backup copy of database is
 a good idea. Do the upgrade to \LB 2.0, optionally you can move the
 database to new OS in this step (see \ref{inst:OSmigration}).
 \item \emph{Before migration some database tuning is
 required.} Especially parameter \texttt{innodb\_buffer\_pool\_size}
 needs to be increased, to support bigger transactions. For details
 see Section~\ref{inst:db_tuning}.
 \item \emph{Database type.} Check if you have a \LB server or a \LB
 proxy. In the following step you must properly set the switch
 \verb'-s' (server) or \verb'-p' (proxy).
 \item \emph{Database conversion.} Use provided shell script (with the proper
  switch from previous step):
  \begin{quote}
  \verb'/opt/glite/etc/glite-lb-migrate_db2version20 {-s|-p}'
  \end{quote}
 \item \emph{(Optional) Drop unnecesary index.} This operation is
  likely to take a lot of time when applied to large database.
  \begin{quote}
  \verb'mysql -u lbserver lbserver20 -e "alter table events drop index host"'
  \end{quote}
 \item \emph{(Optional) Check the \LB indexes.} You may need to add
 LastUpdateTime for monitoring services. See \ref{maintain:index}.
 \item \emph{Start the servers.} MySQL and \LB. Check logs.
\end{itemize}

This migration procedure is tested in following environment: LB 1.9.x
from RPMs SL4 32bit (mysql 4.1.22-2), LB server node, migration to SL5
64bit (mysql 5.0.45-7) LB2.0 RPM. 

%\TODO{automated conversion through YAIM ?}

\subsubsection{Index configuration}

Initial YAIM configuration creates \LB indexes typically,
the actual configuration depends on required features (\eg\ RTM job monitoring).
See Section~\ref{maintain:index} for instructions
on changing \LB server index configuration afterwards in order
to meet specific needs.


\subsubsection{Server superusers}
\label{inst:superusers}

Certain administrative operations (identified below when appropriate) on \LB
server are privileged and special authorization is required to invoke them.
Privileged user can also access job data owned by other users, bypassing the
standard \LB access control mechanisms.  By default, the \LB server identity
(X509 certificate subject name) is considered privileged.  Additional
administrator identities can be specified in a \emph{superusers file},
specified by the \verb'--super-users-file' server option.  A client is granted
superuser privileges if they present credentials matching the superusers
specifications in the file.  The file consists of one or more lines, each one
containing either a subject name or VOMS attribute(s) in the FQAN format (in
the latter case the line must start with \verb'FQAN:').  Note that VOMS anchors
must be configured properly on the \LB machine when FQANs are used.  After
changing the file, the server has to be restarted. 

The default startup script checks for existence of 
/opt/glite/etc/LB-super-users and uses it eventually.

\subsubsection{Authorization of event originators}
\LBold allowed anyone possessing a trusted digital certificate to send an
arbitrary event to the \LB server. While enabling an easy setup, such an
arrangement does not comply with some contemporary requirements, \eg job
traceability, since the data could be distorted by a malicious user.  In order
to strengthen trustworthiness of data provided, the \LBnew server has
introduced an authorization mechanism to control the originators of events.
The authorization model presumes a set of trusted components that are only
allowed to send some types of events, while other types can be logged by any
user. Being based on the LCAS schema~\cite{lcas}, the authorization mechanism
allows to make use standard LCAS plugins, \eg to ban particular users or limit
the service to a specific virtual organization. The \LB server is shipped with
an LCAS plugin providing more fine-grained access control based on event types.

The LCAS-based authorization must be enabled in the \LB configuration.

\TODO{policy format}

% \subsubsection{Notification delivery}\TODO{co tu ma byt?}

\subsubsection{Export to R-GMA}

{\sloppy
\LB server can export information on job state changes to R-GMA infrastructure through \verb'lcgmon' 
in real time. This export is enabled by YAIM by default and uses \verb'GLITE_WMS_LCGMON_FILE' 
environmental variable to retrieve name of log file which is to be consumed by \verb'lcgmon' (usually
\verb'/var/glite/logging/status.log'). The log file has to be rotated regularly.

}

\subsubsection{Data backup}
\label{inst:backup}

Data stored \LB server can be backed up using backups of underlaying database or using \verb'glite-lb-dump' utility.
The latter has some advantages, see Section~\ref{run:dump} for details.

\subsubsection{Purging old data}
\label{inst:purge}

Initial YAIM configuration creates a cron job which runs once a day and purges old 
data (jobs in Cleared state after two days, Aborted and Cancelled after 15 days, and other jobs 
after 60 days of inactivity). It is recommended to run the cron jobs more often (in order to purge less jobs
during single run) if event queue backlogs form in client WMS machines when the purging cron jobs is running.
For details on setting job purge timeouts, see Sect.~\ref{run:purge}.


\subsubsection{Exploiting parallelism}

\LB server uses 10 worker processes (threads) to handle active client accesses (inactive connections are killed
when necessary). Each worker process uses separate connection to database server. Number of worker processes 
can be changed by adding \verb'--slaves' parameter with desired number to servers command line
using \verb'GLITE_LB_SERVER_OTHER_OPTIONS' variable.

\subsubsection{Tuning database engine}
\label{inst:db_tuning}

In order to achieve high performance with LB server underlaying MySQL 
database server has to be configured reasonably well too. 
Default values of some MySQL settings are likely to be suboptimal
and need tuning, especially for larger machines.
These are MySQL configuration variables (to be configured in \texttt{[mysqld]} 
section of \texttt{/etc/my.cnf}) that need tuning most often:
\begin{itemize}
\item \texttt{innodb\_buffer\_pool\_size} -- size of database memory pool/cache. 
It is generally recommended to set it to aroung 75\% of RAM size
(32bit OS/MySQL versions limit this to approx. 2GB due to address space 
constraints).

\item \texttt{innodb\_flush\_log\_at\_trx\_commit} -- frequency of flushing to disk.
Recommended values include:
\begin{itemize}
\item 1 (default) -- flush at each write transaction commit; relatively
slow without battery-backed disk cache but offers highest level of data safety
\item 0 -- flush once per second; fast, use if loss of latest updates on MySQL
or OS crash (e.g. unhandled power outage) is acceptable (database remains consistent)
\end{itemize}

\item \texttt{innodb\_log\_file\_size} -- size of database log file. Larger values
save some I/O activity, but also make database shutdown and crash recovery slower.
Recommended value: 50MB. Clean mysqld shutdown and deletion of log files 
(\texttt{/var/lib/mysql/ib\_logfile*} by default) is necessary before change.

\item \texttt{innodb\_data\_file\_path} -- path to main database file. File on
disk separate from OS and MySQL log files (\texttt{innodb\_log\_group\_home\_dir} variable,
\texttt{/var/lib/mysql/} by default) is recommended.

\end{itemize}

\subsection{\LB proxy}
\label{inst:LBproxy}
TODO: Describe LB Proxy migration here.


All necessary configuration of standalone \LB proxy is done by YAIM,
previous \LB server section applies to merged server+proxy setups (\LBnew only).

\subsection{\LB logger}

All necessary configuration of normal \LB logger is done by YAIM.

\subsection{Smoke tests}

Thorough tests of \LB, including performance measurement, are
covered in the \LB Test Plan document \cite{lbtp}.
This section describes only elementary tests that verify basic
functionality of the services.

The following test description assumes the \LB services installed
and started as described above.

\def\req{\noindent\textbf{Prerequisities:}\xspace}
\def\how{\noindent\textbf{How to run:}\xspace}
\def\result{\noindent\textbf{Expected result:}\xspace}

\subsubsection{Job registration}

Register a~new job with the \LB server and check that its status is
reported correctly.

\req Installed glite-lb-client package, valid user's X509 credentials,
known destination (address:port) of running \LB server.
Can be invoked from any machine.

\how 
\begin{quote}
\verb'/opt/glite/examples/glite-lb-job_reg -m' \emph{server\_name:port}
\end{quote}
A~new jobid is generated and printed.  Run 
\begin{quote}
\verb'/opt/glite/examples/glite-lb-job_status' \emph{jobid}
\end{quote}

\result
The command should report ``Submitted'' job status.

\subsubsection{Logging events via lb-logger}

\label{smoke-log}

Send several \LB events, simulating normal job life cycle.
Checks delivery of the events via \LB logger.

\req Installed glite-lb-client package, valid user's X509 credentials,
known destination (address:port) of running \LB server.
Must be run on a~machine where glite-lb-logger package is set up and running.

\how
\begin{quote}
\verb'/opt/glite/examples/glite-lb-running.sh -m ' \emph{server\_name:port}
\end{quote}

The command prints a~new jobid, followed by diagnostic messages as the events are logged. 
Check the status of the new job with
\begin{quote}
\verb'/opt/glite/examples/glite-lb-job_status' \emph{jobid}
\end{quote}

\result
Due to asynchronous event
delivery various job states can be reported for limited time (several seconds).
Finally the
``Running'' status should be reached.

\subsubsection{Logging events via lb-proxy}

Send events via \LB proxy. Checks the proxy functionality.

\req Running \LB proxy, in standalone package for \LBold, or
\LB server running with \verb'-P' (proxy only) or \verb'-B' (both server and proxy)
options.

\how Similar to Sect.~\ref{smoke-log}:
\begin{quote}
\verb'/opt/glite/examples/glite-lb-running.sh -x -m ' \emph{server\_name:port}
\end{quote}

And check with:
\begin{quote}
\verb'/opt/glite/examples/glite-lb-job_status -x /tmp/lb_proxy_server.sock' \emph{jobid}
\end{quote}


\subsubsection{Notification delivery}

Register for receiving notifications, and log events which trigger
the notification delivery. Checks the whole notification mechanism.
The test is quite complex, though, see notification sections in~\cite{lbug,lbtp}.
