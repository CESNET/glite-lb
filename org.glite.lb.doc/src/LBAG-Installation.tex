%
%% Copyright (c) Members of the EGEE Collaboration. 2004-2010.
%% See http://www.eu-egee.org/partners for details on the copyright holders.
%% 
%% Licensed under the Apache License, Version 2.0 (the "License");
%% you may not use this file except in compliance with the License.
%% You may obtain a copy of the License at
%% 
%%     http://www.apache.org/licenses/LICENSE-2.0
%% 
%% Unless required by applicable law or agreed to in writing, software
%% distributed under the License is distributed on an "AS IS" BASIS,
%% WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
%% See the License for the specific language governing permissions and
%% limitations under the License.
%
\section{Installation and Configuration}

\subsection{Complete list of packages}

\LB is currently distributed mainly in RPMs packages and, since \LBver{3.2} also in \emph{deb} packages. It is available also in
binary form packed as \texttt{.tar.gz}.

In \LBver{1.x}, the list of all LB packages was the following:

\begin{tabularx}{\textwidth}{>{\tt}lX}
glite-lb-common & common files \\ 
glite-lb-client & client library and CLI tools\\ 
glite-lb-client-interface & client library interface (header files) \\ 
glite-lb-harvester & enhanced \LB notification client (since \LBver{1.10}) \\
glite-lb-logger & local-logger and inter-logger \\ 
glite-lb-proxy & proxy (restricted server used by WMS)\\ 
glite-lb-server & server \\ 
glite-lb-server-bones & multi-process server building library \\ 
glite-lb-utils & auxiliary utilities \\ 
glite-lb-ws-interface & web service interface  \\
glite-security-gsoap-plugin & GSS wrapper and GSS plugin for gSoap
\end{tabularx}

Starting with \LBver{2.0}, the code has been restructured quite a lot, especially the dependencies were lightened,
and the new list of packages -- applicable also to \LBver{3.x} is now the following:

\begin{tabularx}{\textwidth}{>{\tt}lX}
glite-lb-doc & documentation \\ 
glite-lb-common & common files \\ 
glite-lb-client & client library and CLI tools\\ 
glite-lb-client-java & Java implementation of the client (since \LBver{2.1})\\ 
glite-lb-harvester & enhanced \LB notification client (since \LBver{2.1})\\
glite-lb-logger & local-logger and inter-logger \\
glite-lb-logger-msg & plugin for message delivery over ActiveMQ (since \LBver{3.0}) \\
glite-lb-server & server, including merged proxy functionality \\
glite-lb-state-machine & state machine and LB plugin for Job Provenance \\ 
glite-lb-utils & auxiliary utilities \\
glite-lb-ws-interface & web service interface \\
glite-lb-yaim & YAIM initialization scripts for \LB (since \LBver{2.1}) \\
glite-lb-nagios-plugins & Nagios plugin that checks the \LB server (since \LBver{3.1}) \\
\end{tabularx}


More detailed description together with the dependencies can be read directly from each package,
for example by issuing the command 
\begin{verbatim}
   rpm -qiR <package_name>
\end{verbatim}

Some of the LB packages depend also on other gLite packages, different 
due to the restructuring since \LBver{2.0}.
For \LBver{1.x} they are:


\begin{tabularx}{\textwidth}{>{\tt}lX}
glite-wms-utils-jobid & gLite jobId management library \\
glite-jp-common & Job Provenance auxiliary library \\ 
\end{tabularx}

\noindent
And for \LBver{2.0 and newer}:

\nopagebreak
\begin{tabularx}{\textwidth}{>{\tt}lX}
glite-jobid-api-c & gLite jobId C API library \\ 
% pro beh LB neni triba
% glite-jp-common & JP common files \\ 
glite-lbjp-common-db & database access layer \\
glite-lbjp-common-jp-interface & interface to the Job Provenance service\\
glite-lbjp-common-log & glite common logging format implementation \\
glite-lbjp-common-maildir & persistent request spool management \\
glite-lbjp-common-server-bones & multi-process server building library \\
glite-lbjp-common-trio & extended printf implementation \\
glite-lbjp-common-gss & GSS wrapper (formerly \emph{glite-security-gss})\\
glite-lbjp-common-gsoap-plugin & GSS plugin for gSoap (formerly \emph{glite-security-gsoap-plugin})\\
\end{tabularx}

where all \verb'glite-lbjp-common-*' packages are common both to \LB and 
Job Provenance (\JP).

\subsubsection{Development packages}

Since \LBver{3.2} development files have been separated from runtime packages, and they are distributed in standalone \texttt{-devel} packages. They are not required for \LB's operation. The following list of development RPMs is given form the sake of completeness:

\begin{tabularx}{\textwidth}{>{\tt}p{6cm}>{\tt}X}
glite-jobid-api-c-devel 
glite-jobid-api-cpp-devel 
glite-lb-client-devel 
glite-lb-common-devel 
glite-lb-logger-devel 
glite-lb-state-machine-devel &
glite-lbjp-common-db-devel 
glite-lbjp-common-gsoap-plugin-devel 
glite-lbjp-common-gss-devel 
glite-lbjp-common-jp-interface-devel 
glite-lbjp-common-log-devel 
glite-lbjp-common-maildir-devel 
glite-lbjp-common-server-bones-devel 
glite-lbjp-common-trio-devel
\end{tabularx}

\subsection{Common logging format}
\label{inst:comlog}
Since \LBver{2.1} \LB service follows the \textbf{gLite common logging recommendations v1.1}:
\begin{center}
\url{https://twiki.cern.ch/twiki/pub/EGEE/EGEEgLite/logging.html}. 
\end{center}

The implementation is done in the \texttt{glite-lbjp-common-log} package and it 
uses \texttt{log4c} (\url{http://log4c.sourceforge.net})
and its configuration file \texttt{log4crc}. 

There is one configuration file \texttt{$[$/opt/glite$]$/etc/glite-lb/log4crc}
that startup scripts use by setting the \texttt{LOG4C\_RCPATH} environment
variable.

A file \texttt{log4crc.example-debugging} may be useful to copy to
\texttt{\$HOME/.log4crc} (or by setting the \texttt{LOG4C\_RCPATH} environment variable
to a directory containing the \texttt{log4crc} file) to obtain detailed debugging output.
One can debug only specific parts of the LB system, for example
by uncommenting \texttt{LB.SERVER.DB} category in the \texttt{log4crc} file,
one gets only the debugging info related to the underlying database subsystem calls.


Currently supported log categories are:

\nopagebreak
\begin{tabularx}{\textwidth}{>{\tt}lX}
SECURITY & Security matters \\
ACCESS & Communication issues \\
CONTROL & \LB server control \\
LB & \emph{unused} \\
LB.LOGD & Messages from the \LB local logger \\
LB.INTERLOGD & Messages from the \LB interlogger \\
LB.NOTIFINTERLOGD & Messages from the notification interlogger \\
LB.SERVER & Processing within the \LB server \\
LB.SERVER.DB & DB calls made by the server \\
LB.SERVER.REQUEST & Processing \LB server requests \\
LB.HARVESTER & Messages from the \LB harvester \\
LB.HARVESTER.DB & DB calls made by the harvester \\
LB.AUTHZ & Authentication matters \\
\end{tabularx}

The following log priorities are recognized, in a descending order of severity: \texttt{fatal}, \texttt{error}, \texttt{warn}, \texttt{info}, \texttt{debug}. Note that running with any of the logging categories set do \texttt{debug} for a prolonged period of time will result in the logfile growing uncontroledly.

In a typical setup, logging messages generated by the \LB service will be found in \texttt{/var/log/messages}.

\note\ \emph{syslog} is typically configured to drop log messages with priority \texttt{debug}. You may want to enable it, for example by using something like this in \texttt{/etc/syslog.conf} and then restarting {syslog}:
\begin{verbatim}
*.debug;mail.none;authpriv.none;cron.none                -/var/log/messages
\end{verbatim}

\subsection{\LB server}

\subsubsection{Hardware requirements}
\label{inst:hw_req}

Hardware requirements depend on performance and storage time requirements.
Disk space used by LB server consists of database space and working space 
for backup dumps and temporary files used by exports to Job Provenance and
R-GMA tables. Necessary database space can be calculated by multiplying 
job retention length (job purge timeout), job submission rate, and  
per-job space requirements (120\,KB per job is recommended for current common 
EGEE usage pattern; jobs can consume more than that with use of very long
JDL descriptions, user tags, or very high number of resubmissions).
For temporary files, approximately 10\,GB is sufficient for LB server setups
working normally, more can be needed when backlog forms in data export
to any external service. For example, typical setup processing 40\,000 jobs per 
day where all jobs are purged after 10 days needs about 58 gigabytes
($10 \cdot 40000 \cdot 120 \mbox{KB (per job)} + 10$) not accounting for operating 
system and system logs.

For smooth handling of 40\,000 jobs/day, this or better machine configuration 
is necessary:
\begin{itemize}
\item 1GB RAM
\item CPU equivalent of single Xeon/Opteron 1.5GHz
\item single 7200 rpm SATA disk.
\end{itemize}
In order to achieve higher performace, following changes are recommended:
\begin{itemize}
\item Faster disks. Disk access speed is crucial for LB server, couple of 15k rpm
SCSI or SAS disks (one for MySQL database data file, the second for DB logs, LB server's
working directories, and operating system files) or RAID with battery backed 
write-back cache is preferable.
\item More memory. Large RAM improves performance through memory caching,
relative speed gain is likely to be rougly proportional to memory/database size ratio.
To use 3\,GB or more efficiently, 64bit OS and MySQL server versions are recommended.
\item Faster or more processors. CPU requirements scale approximately linearly with
offered load.
\end{itemize}

\subsubsection{Standard Installation}

\begin{itemize}
\item Installing from \textbf{EMI or UMD repository} (applies to \LBver{3.0} and higher):

Install and configure a clean system, the \textbf{EPEL} repository, and the \textbf{EMI} repository as per instructions given in \htmladdnormallink{https://twiki.cern.ch/twiki/bin/view/EMI/GenericInstallationConfigurationEMI1}{https://twiki.cern.ch/twiki/bin/view/EMI/GenericInstallationConfigurationEMI1}. Then install metapackage \texttt{emi-lb}.

\item Installing from \textbf{gLite's node-type repository} (applies to \LBver{up to 2.1}):
% XXX Don't forget to increase version if ever LB 3 releases with gLite

Install and configure OS and basic services (certificates, CAs, time synchronization, software repositories) according to the \htmladdnormallink{https://twiki.cern.ch/twiki/bin/view/LCG/GenericInstallGuide320}{https://twiki.cern.ch/twiki/bin/view/LCG/GenericInstallGuide320}. Then install metapackage \texttt{glite-LB} from an appropriate gLite software repository.

\end{itemize}

YAIM configuration can be done then:

\begin{quote}
\texttt{/opt/glite/yaim/bin/yaim -c -s site-info.def -n glite-LB}
\end{quote}

Available parameters specific to LB server are (mandatory parameters are \textbf{highlighted}):

%variable&meaning&default value &further details\\
\begin{itemize}
\item \textbf{MYSQL\_PASSWORD} -- root password of MySQL server (mandatory)
\item \texttt{GLITE\_LB\_EXPORT\_PURGE\_ARGS} -- purge timeouts (default: \texttt{--cleared 2d --aborted 15d --cancelled 15d --other 60d})

According to local retention policy you may want to use different purge timeouts (for example WLCG would need \texttt{--cleared 90d --aborted 90d --cancelled 90d --other 90d}).
\item \texttt{GLITE\_LB\_EXPORT\_ENABLED} -- set to \texttt{true} for export to JP, installed glite-lb-client and glite-jp-client are needed (default: \texttt{false})
\item \texttt{GLITE\_LB\_EXPORT\_JPPS} -- Job Provenance Primary Storage where to export purged jobs, required if export to JP is enabled
\item \texttt{GLITE\_LB\_RTM\_ENABLED} -- enable settings for Real Time Monitor - indexes and additional access (default: false)
\item \texttt{GLITE\_LB\_TYPE} -- type of the \LB service: server, proxy, both (default: autodetect, \LB node only: 'server', WMS node only: proxy, \LB and WMS: 'both')
\item \texttt{GLITE\_LB\_INDEX\_OWNER} -- when specified, add (\texttt{true}) or drop (\texttt{false}) 'owner' index (default: 'owner' index not touched)
\item \texttt{GLITE\_LB\_MSG\_BROKER} -- URL of the MSG broker, 'auto' for looking in BDII, 'false' for disabling MSG notifications (default: auto)
\item \texttt{GLITE\_LB\_MSG\_NETWORK} -- required network type when searching in BDII (default: PROD)
\item \texttt{LCG\_GFAL\_INFOSYS} -- BDII servers (default: lcg-bdii.cern.ch:2170)
\end{itemize}

Authorization:
\begin{itemize}
\item \texttt{GLITE\_LB\_SUPER\_USERS} -- additional super-users (default: empty)\footnote{The use of this parameter is a FAQ. See section \ref{FAQ:WMS_superusers}.}
\item \texttt{GLITE\_LB\_WMS\_DN} -- DNs of WMS servers (default: empty)\footnotemark[\thefootnote]
\item \texttt{GLITE\_LB\_RTM\_DN} -- DNs using to get notifications from \LB server\\
(default: \texttt{heppc24.hep.ph.ic.ac.uk} machine certificate)
\item \texttt{GLITE\_LB\_AUTHZ\_<category>} -- more detailed tuning of access grants, see Section~\ref{inst:authz} (default: empty, '\texttt{.*}' for logging and job registrations)
\end{itemize}

Additional helper or legacy parameters:
\begin{itemize}
\item \texttt{GLITE\_LB\_LOCATION} -- \LB prefix (default: \texttt{/opt/glite} or \texttt{/usr})
\item \texttt{GLITE\_LB\_LOCATION\_ETC} -- system config directory (default: \texttt{/opt/glite/etc} or \texttt{/etc})
\item \texttt{GLITE\_LB\_LOCATION\_VAR} -- gLite local state directory (default: \texttt{/opt/glite/var} or \texttt{/var/glite})
\item \texttt{GLITE\_JP\_LOCATION} -- can be used when JP subsystem location differs from LB (default: empty)
\item \texttt{GLITE\_LB\_HARVESTER\_ENABLED} -- set to \texttt{true} for sending notifications, used mainly for legacy export to MSG publish system (default: \texttt{false})
\item \texttt{GLITE\_LB\_HARVESTER\_MSG\_OPTIONS} -- additional options for MSG publish (default: \texttt{--wlcg})
\item \texttt{GLITE\_WMS\_LCGMON\_FILE} -- pathname of file where job state
export data are written for use by lgcmon/R-GMA 
(default: \texttt{/var/glite/logging/status.log}). \emph{Note: This feature is now obsolete and only available in \LBver{1.x}.}
\end{itemize}


In addition to those, YAIM LB module uses following parameters:
\begin{itemize}
\item \texttt{INSTALL\_ROOT} -- installation root, shouldn't be changed (default: '/opt' or '/')
\item \texttt{GLITE\_LOCATION\_VAR} -- directory for local state files (default: '/opt/glite/var' or '/var/glite')
\item \texttt{GLITE\_USER} -- unprivileged user name (default: 'glite')
\item \textbf{SITE\_NAME} -- site name (mandatory)
\item \textbf{SITE\_EMAIL} -- site email, for cron scripts (mandatory)
\end{itemize}

Lists are separated by comma.

\subsubsection{Configuration Files}

Using \emph{yaim}, you do not need to edit \LB's configuration files for your installation to work. On the other hand, if you cannot use \emph{yaim}, you may configure your \LB server through config files detailed bellow. Since \LBver{3.0} configuration files are located in \texttt{/etc/glite-lb/}.

\begin{tabularx}{\textwidth}{>{\tt}lX}
glite-lb-authz.conf & Authorization policy, in use since \LBver{2.1}. Extensively explained in Section \ref{inst:authz} (page \pageref{inst:authz}).\\
log4crc & Logging output configuration, in use since \LBver{2.0}. Explained in Section \ref{inst:comlog} (page \pageref{inst:comlog}).\\
msg.conf & Messaging plugin and features configuration, in use since \LBver{3.0}. Explained in Section \ref{inst:messaging} (page \pageref{inst:messaging}).\\
site-notif.conf & Permanent notification registrations to be maintained on the server. Available since \LBver{3.2}. Explained in section \ref{inst:sitenotif} (page \pageref{inst:sitenotif}).\\
%glite-lb-my.cnf & Pre-prepared \emph{MySQL} configuration file, designed to be included in \texttt{my.cnf} by the \texttt{!include} directive. Available since \LBver{3.2}.\\
html-header.html & Recognized since \LBver{3.3}; optional HTML header to be included in all \LB server's HTML output. Explained in section \ref{inst:branding} (page \pageref{inst:branding}).
\end{tabularx}

Besides configuration files observed directly by \LB's services, there is a score of other files installed by \LB and used by other system services. They are:

\newcounter{initdfootnote}
\begin{tabularx}{\textwidth}{>{\tt}lX}
/etc/cron.d/glite-lb-purge.cron & Nightly execution of the \LB purger (see Section \ref{inst:purge}).\\
/etc/cron.d/locallogger.cron & Prevent stale handle on \texttt{hostcert.pem} by running a \texttt{touch} on it quarter-daily.\\
/etc/cron.d/glite-lb-notif-keeper.cron & Refresh registration of \LB notifications set up by site admins py regular calls to \texttt{glite-lb-notif-keeper}. Present since \LBver{3.2}\\
/etc/init.d/glite-lb-bkserverd & Start up the \LB server. Many command line options are hard-coded in the script.\footnotemark\setcounter{initdfootnote}{\thefootnote}\\
/etc/init.d/glite-lb-harvester & Start up the \LB harvester. Some command line options are hard-coded in the script.\footnotemark[\theinitdfootnote]\\
/etc/init.d/glite-lb-locallogger & Start up the \LB local logger. Some command line options are hard-coded in the script.\footnotemark[\theinitdfootnote]
\end{tabularx}
\footnotetext{When using \emph{yaim}, these scripts are generated and command line options inserted by \emph{yaim}.}

\input{https_configuration}

\subsubsection{Migration to a Different OS Version}
\label{inst:OSmigration}
Migration of a LB server to different machine is possible using
following simple procedure (just file copy of the MySQL database). We
tested the migration from SL4 32bit (mysql 4.1.22-2) to SL5 64bit
(mysql 5.0.45-7).

Steps:
\begin{itemize}
\item \emph{Prepare a new machine.} The new machine must get the same hostname 
 as the old machine had. It is a part of job ids stored in the database.
\item \emph{Move data.} Just stop the MySQL server and move
 \verb'/var/lib/mysql' data directory directly to the target machine.
\item \emph{(optional) Restore file contexts.} You may need to restore file 
 contexts in case of enabled SELinux.
\end{itemize}
For example, commands on the target machine:
 \begin{verbatim}
 service mysqld stop
 cd /var/lib
 tar xf /tmp/lb.tar
 restorecond -R mysql
 service mysqld start
 \end{verbatim}

\subsubsection{Migration of database to support transactions}
Started from version 1.4.3 of the \texttt{glite-lb-server}
package, the \LB server introduced optional use of database
transactions for \LB database updates in order to improve their
performace. This feature is switched on by default when underlying
MySQL database uses transactional InnoDB tables. For new
installations, YAIM configuration process will create transactional
database automatically. For existing LB server database the migration 
process is not automatically handled.

Note: If you want to add transactions when migrating to \LBver{2.0 or higher} skip
this section and use \LBver{2.x} migration procedure. The migration of
database to support transactions is included ini that procedure.

Steps:
\begin{itemize}
 \item \emph{Stop the server.} Stop both a \LB server and a MySQL
 server. Making a fresh backup copy of database is a good idea.
 \item \emph{Database conversion.} Use provided SQL script:
  \begin{quote}
   \begin{verbatim}
mysql -u lbserver lbserver20 \
        <[/opt/glite]/etc/glite-lb-dbsetup-migrate2transactions.sql
   \end{verbatim}
  \end{quote}
 \item \emph{Start the servers.} MySQL and \LB. Check logs.
\end{itemize}


\subsubsection{Migration to \LB 2.x}
\label{inst:migrate20}
The migration process of existing \LB 1.x database to the \LB 2.x is
not handled automatically. The database schema change is required due
to support of merged \LB server and proxy services using single
database, pointers to purged jobs (``zombies'') and other
improvements.

Warning: There are two types of \LB database based on the fact that
you can have a \LB server or \LB proxy. For more information about \LB
proxy please see \ref{inst:LBproxy}

Steps:
\begin{itemize}
 \item \emph{Stop the server and upgrade to \LB 2.x.} Stop both a \LB
 server and a MySQL server. Making a fresh backup copy of database is
 a good idea. Do the upgrade to \LB 2.x, optionally you can move the
 database to new OS in this step (see \ref{inst:OSmigration}).
 \item \emph{Before migration some database tuning is
 required.} Especially parameter \texttt{innodb\_buffer\_pool\_size}
 needs to be increased, to support bigger transactions. For details
 see Section~\ref{inst:db_tuning}
 \item \emph{Database type.} Check if you have a \LB server or a \LB
 proxy. In the following step you must properly set the switch
 \verb'-s' (server) or \verb'-p' (proxy).
 \item \emph{Database conversion.} Use provided shell script (with the proper
  switch from previous step):
  \begin{quote}
  \verb'[/opt/glite]/etc/glite-lb-migrate_db2version20 {-s|-p}'
  \end{quote}
 \item \emph{(Optional) Drop unnecesary index.} This operation is
  likely to take a lot of time when applied to large database.
  \begin{quote}
  \verb'mysql -u lbserver lbserver20 -e "alter table events drop index host"'
  \end{quote}
 \item \emph{(Optional) Check the \LB indexes.} You may need to add
 LastUpdateTime for monitoring services. See \ref{maintain:index}
 \item \emph{Start the servers.} MySQL and \LB. Check logs.
\end{itemize}

This migration procedure is tested in following environment: LB 1.9.x
from RPMs SL4 32bit (mysql 4.1.22-2), LB server node, migration to SL5
64bit (mysql 5.0.45-7) LB2.0 RPM. 

\subsubsection{Migration to \LB 3.x}
\label{inst:migrate30}
There are no specific configuration changes required when migrating from \LBver{2.x} to \LBver{3.x}. In case you wish to migrate from \LBver{1.x}, follow instructions given in section \ref{inst:migrate20} but upgrade directly to \LBver{3.0} in the first step.

\emph{Note:} Upgrading from \LBver{2.x} provided by gLite \LB node repository to \LBver{3.0 or higher} provided by the EMI repository has never been tested.

\subsubsection{Migration to \LB 4.x}
\label{inst:migrate40}
There was a change in the database schema between \LBver{3.x} and \LBver{4.x}. This procedure applies to upgarding from \LBver{2.x and 3.x}. To upgrade from \LBver{1.x}, first follow the instructions for upgrading from \LBver{1.x} to \LBver{2.x} (Section~\ref{inst:migrate20}, page~\pageref{inst:migrate20}) and then continue here.

The change is rather straightforward. When migrating from previous versions, perform a distribution update. Then stop the \LB server, run the DB migration script, and start the \LB server again:

\begin{verbatim}
/etc/init.d/glite-lb-bkserverd stop
glite-lb-migrate_db2version40
/etc/init.d/glite-lb-bkserverd start
\end{verbatim}

%\TODO{automated conversion through YAIM ?}

\subsubsection{Connecting to the Messaging Infrastructure}
\label{inst:messaging}

As of \LBver{3.0}, the \LB server node becomes a producer of messages, which it delivers into the messaging infrastructure.

Correct broker settings are infered from BDII by YAIM on configuration. By default, messaging-related settings are stored in file:

  \begin{quote}
	\begin{verbatim}
[/opt/glite]/etc/glite-lb/msg.conf
	\end{verbatim}
  \end{quote}

Overall, \texttt{msg.conf} specifies the following information:

\begin{itemize}
\item The messaging plugin to be used by the notification interlogger. Plugin settings should be correct \emph{ab initio} and do not require modification by administrators.
\item Broker settings (attribute \texttt{broker}). They may require an adaptive change in case the currently configured broker disappears and automatic checks fail to switch the settings to another one on time.
\item Permissible topic title prefixes (attribute \texttt{prefix}). Registrations for delivery to topics not matching the prefix will be rejected. In case no prefix is specified, \LB applies the default EGI prefix: \texttt{grid.emi.}
\end{itemize}
Note: Current broker and prefix settings can be retrieved from the \LB server by any authenticated user reading the server's configuration page -- see Section \ref{s:findbroker}.


\subsubsection{Messaging: Persistent Registration for Notifications}
\label{inst:sitenotif}

Starting with \LBver{3.2} there is a mechanism for site admins to set up and maintain ``permanent'' registrations for notifications, which should be always kept active on the server. A maintainer script regularly checks existing registrations, extends their validity, and sets up new registrations.

The process is governed by a separate configuration file \texttt{/etc/glite-lb/site-notif.conf}. The format of the file is simple, one line per registration, with each line giving a single-word handle and a list of arguments to use for registration.\footnote{Command \texttt{glite-lb-notify} is used to make the registrations. See \cite{lbug} for applicable arguments.}

For instance the following line in \texttt{/etc/glite-lb/site-notif.conf}:

\begin{verbatim}
testnotif       --state running -c -N -a x-msg://grid.emi.lbexample
\end{verbatim}

\indent{}will set up and maintain registration for messages to be generated whenever a job changes state (\texttt{-c}) to \emph{running} (\texttt{-{}-state running}). Messages will be delivered to topic \texttt{grid.emi.lbexample} and user identification (DN) will be replaced with a hash (\texttt{-N}). The word \texttt{testnotif} is just a plain-text handle.

In another practical example, the following line in \texttt{/etc/glite-lb/site-notif.conf}:

\begin{verbatim}
voDboard        -T -v testvo -a x-msg://grid.emi.testvo.dashboard
\end{verbatim}

\indent{}will set up and maintain registration for messages to be generated whenever a job belonging to VO \emph{testvo} (\texttt{-v testvo}) reaches a terminal state (\texttt{-T}),\footnote{Terminal states are recognized by the server. As of \LBver{3.2} they are: \emph{cleared}, \emph{aborted}, \emph{canceled} and \emph{purged}.} and delivered to topic \texttt{grid.emi.testvo.dashboard}. Again, the word \texttt{voDboard} is simply a plain-text handle.

The maintainer script \texttt {glite-lb-notif-keeper} runs regularly and makes sure that registrations do not expire and that the messaging infrastructure keeps receiving them. In case of a listener (messaging broker) being unavailable for a prolonged period of time, the registration is terminated to prevent build-up of undelivered messages. A new registration will be created next time round, and if the listener comes up before then, normal operation will resume.

\paragraph{Applying changes} After changing the \texttt{site-notif.conf} file, the simplest option is to do nothing and wait for \emph{cron} to invoke the maintainer script \texttt{glite-lb-notif-keeper}. You may also run the script manually from the command line. The script handles newly added registrations as well as registrations whose conditions have changed. It does not deal with registrations (lines) removed from the configuration file, though. Those are simply left to expire, typically 12 hours after the latest renewal. In case immediate removal is required, you need to drop the existing registration using \texttt{glite-lb-notify drop}.\footnote{Note that the server's identity is used to create the registrations, i.e. that the server is the owner. You may need to supply the server's identity to be able to remove a problematic registration.}

\subsubsection{Index configuration}

Initial YAIM configuration creates \LB indexes typically,
the actual configuration depends on required features (\eg\ RTM job monitoring).
See Section~\ref{maintain:index} for instructions
on changing \LB server index configuration afterwards in order
to meet specific needs.

\subsubsection{Authorization policy}
\label{inst:authz}
The \LB server applies a quite strict access control policy on the
operations provided to the clients to ensure a sufficient level of data
protection. By default, the information about a job is only available to the
owner of the job. The job owner can specify an ACL assigned to their jobs
specifying permissions granted to other users so that they could access the
job records, too. More information about the ACL management can be found in
the \LB Users' guide.

Apart from using the ACLs, the \LB server administrator can also set a
server-level policy granting rights to perform particular operation on \LB
server that are considered privileged.
For example, a privileged
user can access data about jobs owned by other users, bypassing the default
\LB access control mechanism. \LBver{2.1} specifies several categories of
rights that can be granted to the users:

\begin{itemize}
\item \verb'ADMIN_ACCESS'
\item \verb'READ_ALL'
\item \verb'PURGE'
\item \verb'STATUS_FOR_MONITORING'
\item \verb'GET_STATISTICS'
\item \verb'REGISTER_JOBS'
\item \verb'LOG_WMS_EVENTS'
\item \verb'LOG_CE_EVENTS'
\item \verb'LOG_GENERAL_EVENTS'
\item \verb'GRANT_OWNERSHIP' (since \LBver{3.0})
\item \verb'READ_ANONYMIZED' (since \LBver{3.2})
\end{itemize}

The first action disables all authorization checks. The next four categories concern with acquring data from the \LB
server, while the other ones make it possible to define a web of trusted sources
passing events to the \LB server.

\verb'ADMIN_ACCESS' is the most powefull privilege allowing to bypass any
authorization checks on the server. It replaces the superuser role, which
existed in \LBver{2.0} and older. Note, that the \verb'--super-users'
command-line option still exists and translates internally into granting
\verb'ADMIN_ACCESS'.

\verb'READ_ALL' enables to access all job information stored on the server.
\verb'PURGE' grants the privilege to ask for purging the \LB database.  The \LB
server's identity is automatically assigned the \verb'READ_ALL' and
\verb'PURGE' so that these operations are available \eg to a cron script
running on \LB node.

When granted to a user, the \verb'STATUS_FOR_MONITORING' right allows the user to
query statuses of all jobs maintaned by the server, however only a small
subset of the status fields is returned to back. For example, the caller
does not obtain the identity of the job owner. The purpose of this right is
to provide a way to collect information necessary for overall monitoring
while preserving a basic level of privacy.

\verb'GET_STATISTICS' allows its bearers to query for on-line statitistics
generated by the \LB server. See~\ref{maintain:statistics} for more
information about the purpose of the function.

\verb'READ_ANONYMIZED' allows reading access to job information on the server,
but only in an anonymized form (user identification hashed).

\LBver{1.x} allowed anyone possessing a trusted digital certificate to send an
arbitrary event to the \LB server. While enabling an easy setup, such an
arrangement does not comply with some contemporary requirements, \eg job
traceability, since the data could be distorted by a malicious user.  In order
to strengthen the trustworthiness of the data provided, the \LBver{2.1}
server has introduced an authorization mechanism to control the originators
of events.  The authorization model presumes a set of trusted components
that are only allowed to send ``important'' events, while other types can be
logged from any source. The \verb'REGISTER_JOBS' authorization category
specifies clients allowed to register jobs with the \LB server. The
\verb'LOG_CE_EVENTS' category makes it possible to define a set of trusted
CEs that are allowed to log events originating from within sites (in
particular \verb'RUNNING', \verb'REALLYRUNNING', and \verb'DONE').
Similarly, the \verb'LOG_WMS_EVENTS' category defines a web of trusted WMS
nodes. The \verb'LOG_GENERAL_EVENTS' category comprises events that can be
sent from any place on the grid, namely \verb'CURDESC', \verb'USERTAG', and
\verb'CHANGEACL'. It is important to understand that these access control
rules provides additional level to the existing authorization routines.
In particular, being granted the \verb'LOG_GENERAL_EVENTS' right is not sufficient to
e.g. change ACLs on jobs of other people and obtain an access to the job information.

As of \LBver{3.0} it is possible for the job owner to hand over the ownership
of the payload to another user, which eases handling \eg of pilot jobs. In
order to set the payload owner, the job owner must log a
\verb'GrantPayloadOwnership' event, where the identity of the new
payload owner is introduced. The event can only originate from loggers
described by the \verb'GRANT_OWNERSHIP' category of the policy file. More
information and an example of ownership setting is given in the \LB Users'
guide.

The \LB policy is specified in a policy configuration file that must be given
in the server configuration. Specifying the policy file also triggers the
enforcement of access policy rights, especially the ones describing the event
sources. If the policy is not enabled, the \LB server accepts events from any
logger with a trusted certificate. The format of the policy is a subset of the
Simplified policy langauge introduced by the Argus gLite authorization
service\footnote{\url{https://twiki.cern.ch/twiki/bin/view/EGEE/SimplifiedPolicyLanguage}}.
Unlike the Argus language, the \LB policy supports only certificate subject
names and VOMS fully qualified attribute names (FQANs) to describe the users
and do not support 'deny'ing of rights.  Also, general regular expressions
cannot be used in the argument, only the \verb'".*"' wild card is supported. An
example of the policy file follows:

\begin{lstlisting}
resource "LB" {
    action "ADMIN_ACCESS" {
	rule permit {
	     subject = "/DC=cz/DC=cesnet-ca/O=CESNET/CN=Daniel Kouril"
        }
	rule permit {
	     fqan = "/vo/Role=Manager"
        }
    }
    action "STATUS_FOR_MONITORING" {
        rule permit {
             fqan = "/vo/monitoring"
        }
        rule permit {
             fqan = "/TEST/rtm"
        }
    }
    action "LOG_WMS_EVENTS" {
        rule permit {
             subject = "/DC=cz/DC=cesnet-ca/O=CESNET/CN=wms01.cesnet.cz"
        }
    }
    action "LOG_GENERAL_EVENTS" {
        rule permit {
             subject = ".*"
        }
    }
    action "REGISTER_JOBS" {
        rule permit {
             subject = ".*"
        }
    }
    action "GRANT_OWNERSHIP" {
        rule permit {
             fqan = "/VO/Pilot_job_factory"
        }
    }
}
\end{lstlisting}

After changing the file, the server has to be restarted.

In order to provide yet additional level of authorization, the LCAS
schema\cite{lcas} is still used in the server. If enabled in configuration,
it can be used to specify more general settings using the standard LCAS
modules and e.g. blacklist particular users. The standard LCAS documentation
should be followed to set up the LCAS layer properly.

% \subsubsection{Notification delivery}\TODO{co tu ma byt?}

\subsubsection{Export to R-GMA}

\emph{Note: This feature is now obsolete and only available in \LBver{1.x}.}

{\sloppy
\LB server can export information on job state changes to R-GMA infrastructure through \verb'lcgmon' 
in real time. This export is enabled by YAIM by default and uses \verb'GLITE_WMS_LCGMON_FILE' 
environmental variable to retrieve name of log file which is to be consumed by \verb'lcgmon' (usually
\verb'/var/glite/logging/status.log'). The log file has to be rotated regularly.

}

\subsubsection{Data backup}
\label{inst:backup}

Data stored \LB server can be backed up using backups of underlaying database or using \verb'glite-lb-dump' utility.
The latter has some advantages, see Section~\ref{run:dump} for details.

\subsubsection{Purging old data}
\label{inst:purge}

Initial YAIM configuration creates a cron job which runs once a day and purges old 
data (jobs in Cleared state after two days, Aborted and Cancelled after 15 days, and other jobs 
after 60 days of inactivity). It is recommended to run the cron jobs more often (in order to purge less jobs
during single run) if event queue backlogs form in client WMS machines when the purging cron jobs is running.
For details on setting job purge timeouts, see Sect.~\ref{run:purge}


\subsubsection{Exploiting parallelism}

\LB server uses 10 worker processes (threads) to handle active client accesses (inactive connections are killed
when necessary). Each worker process uses separate connection to database server. Number of worker processes 
can be changed by adding \verb'--slaves' parameter with desired number to servers command line
using \verb'GLITE_LB_SERVER_OTHER_OPTIONS' variable.

\subsubsection{Tuning database engine}
\label{inst:db_tuning}

In order to achieve high performance with LB server underlaying MySQL 
database server has to be configured reasonably well too. 
Default values of some MySQL settings are likely to be suboptimal
and need tuning, especially for larger machines.
These are MySQL configuration variables (to be configured in \texttt{[mysqld]} 
section of \texttt{/etc/my.cnf}) that need tuning most often:
\begin{itemize}
\item \texttt{innodb\_buffer\_pool\_size} -- size of database memory pool/cache. 
It is generally recommended to set it to aroung 75\% of RAM size
(32bit OS/MySQL versions limit this to approx. 2GB due to address space 
constraints).

\item \texttt{innodb\_flush\_log\_at\_trx\_commit} -- frequency of flushing to disk.
Recommended values include:
\begin{itemize}
\item 1 (default) -- flush at each write transaction commit; relatively
slow without battery-backed disk cache but offers highest level of data safety
\item 0 -- flush once per second; fast, use if loss of latest updates on MySQL
or OS crash (e.g. unhandled power outage) is acceptable (database remains consistent)
\end{itemize}

\item \texttt{innodb\_log\_file\_size} -- size of database log file. Larger values
save some I/O activity, but also make database shutdown and crash recovery slower.
Recommended value: 50MB. Clean mysqld shutdown and deletion of log files 
(\texttt{/var/lib/mysql/ib\_logfile*} by default) is necessary before change.

\item \texttt{innodb\_data\_file\_path} -- path to main database file. File on
disk separate from OS and MySQL log files (\texttt{innodb\_log\_group\_home\_dir} variable,
\texttt{/var/lib/mysql/} by default) is recommended.

\end{itemize}

\subsubsection{Branding \LB's HTML output}
\label{inst:branding}

Since \LBver{3.3}, the server allows site admins to specify header files to be used in all HTML output, branding it with their home organization's visual style or logos. The server looks for the file at \texttt{/etc/glite-lb/html-header.html} but option \texttt{-H} can be used to specify a different location. The contents of the file are inserted verbatim between the \texttt{<head>} and \texttt{</head>} tags and typically they will give a \texttt{<style>} definition. 

The include file's existence is checked on server startup, meaning that it must exist at that moment to be used in the session at all. It is not stored in memory, however, but rather read again from disk every time HTML output is being generated. This simplifies debugging/development of the style file.

It is important to note that \LB does in no way parse the file. It simply includes it ``as is'' and making the resulting output valid is the sole responsibility of the site administrator.

\subsection{\LB proxy}
\label{inst:LBproxy}
% TODO: Describe LB Proxy migration here.


All necessary configuration of \LB proxy is done by YAIM,
and described with gLite WMS installation elsewhere.
Previous \LB server section applies to merged server+proxy setups (since \LBver{2.0}).

A~special care must be taken when an existing \LB proxy database
is migrated to \LBver{2.x}.
In general, this is not a~typical scenario -- \LBver{2.x} server in proxy mode
on WMS node is introduced with a~major WMS upgrade, and it is expeced
to be installed from scratch rather than migrated, preserving \LB proxy data.

If the migration is really needed, \verb'glite-lb-migrate_db2version20'
script should be run with~\verb'-p' (Sect~\ref{inst:migrate20}).
However, the \LB database name remains \verb'lbproxy' while
the \LBver{2.x} binaries expect unified \verb'lbserver20' by default.
Because renaming a~MySQL database is a~non-trivial, error prone task,
the recommended workaround is to add the following variable setting

\verb'GLITE_LB_SERVER_OTHER_OPTIONS="--mysql lbserver/@localhost:lbproxy"' 

into the gLite startup environment (\verb'[/opt/glite]/etc/profile.d') instead.
This setting makes \LB server use the \verb'lbproxy' database instead of the default.

\subsection{\LB logger}

All necessary configuration of normal \LB logger is done by YAIM.

\subsection{\LB harvester}

\LB Harvester gathers information about jobs from \LB servers using efficient
\LB notification mechanism. It manages notifications and keeps them in
a persistent storage (file or database table) to reuse later on next launch.
It takes care of refreshing notifications and queries \LB servers back when
some notification expires.

It is not intended for normal usage. You will need Harvester for sending notifications to MSG publish infrastructure, but only for older \LB server releases (gLite 3.1.x, support since gLite 3.1.19). Example of YAIM configuration:

\begin{verbatim}
GLITE_LB_HARVESTER_ENABLED=true
GLITE_LB_HARVESTER_MSG_OPTIONS="--wlcg-topic=org.wlcg.usage.jobStatus 
 --wlcg-config=/etc/msg-publish/msg-publish.conf 
 --wlcg-binary=/usr/bin/msg-publish"
\end{verbatim}

Since gLite 3.2.1, \LB Harvester is not needed for MSG publish. Notifications are reliably delivered by interlogger instead. Delivery can be switched on in this case by \texttt{GLITE\_LB\_MSG\_ENABLED} and \texttt{GLITE\_LB\_MSG\_BROKER} YAIM options.

\subsection{Smoke tests}

Thorough tests of \LB, including performance measurement, are
covered in the \LB Test Plan document \cite{lbtp}.
This section describes only elementary tests that verify basic
functionality of the services.

The following test description assumes the \LB services installed
and started as described above.

\def\req{\noindent\textbf{Prerequisities:}\xspace}
\def\how{\noindent\textbf{How to run:}\xspace}
\def\result{\noindent\textbf{Expected result:}\xspace}

\subsubsection{Job registration}

Register a~new job with the \LB server and check that its status is
reported correctly.

\req Installed glite-lb-client package, valid user's X509 credentials,
known destination (address:port) of running \LB server.
Can be invoked from any machine.\newcounter{examplesfootnote}
\footnote{Example scripts or binaries used here can be found either
in \texttt{/opt/glite/examples} (if installed from a LB node repository) or
\texttt{/usr/lib64/glite-lb/examples} (if installed from the EMI repository). Please note that these examples are primarily intended for developers, and their use (e.g. command line options) is not covered by documentation execpt for these few specific use cases.}\setcounter{examplesfootnote}{\thefootnote}

\how 
\begin{quote}
\texttt{glite-lb-job\_reg -m} \emph{server\_name:port} \texttt{-s Application}
\end{quote}
A~new jobid is generated and printed.  Run 
\begin{quote}
\verb'glite-lb-job_status' \emph{jobid}
\end{quote}

\result
The command should report ``Submitted'' job status.

\subsubsection{Logging events via lb-logger}

\label{smoke-log}

Send several \LB events, simulating normal job life cycle.
Checks delivery of the events via \LB logger.

\req Installed package \texttt{glite-lb-client}, valid X509 credentials,
known destination (address:port) of running \LB server.
Must be run on a~machine where \texttt{glite-lb-logger} package is set up and running.\footnotemark[\theexamplesfootnote]

\how
\begin{quote}
\texttt{glite-lb-running.sh -m} \emph{server\_name:port}
\end{quote}

The command prints a~new jobid, followed by diagnostic messages as the events are logged. 
Check the status of the new job with
\begin{quote}
\verb'glite-lb-job_status' \emph{jobid}
\end{quote}

\result
Due to asynchronous event
delivery various job states can be reported for limited time (several seconds).
Finally the
``Running'' status should be reached.

\subsubsection{Logging events via lb-proxy}

Send events via \LB proxy. Checks the proxy functionality.

\req Running \LB proxy, in standalone package for \LBver{1.x}, or
\LB server running with \verb'-P' (proxy only) or \verb'-B' (both server and proxy)
options.\footnotemark[\theexamplesfootnote]

\how Similar to Sect.~\ref{smoke-log}:
\begin{quote}
\verb'glite-lb-running.sh -x -m ' \emph{server\_name:port}
\end{quote}

And check with:
\begin{quote}
\verb'glite-lb-job_status -x /tmp/lb_proxy_server.sock' \emph{jobid}
\end{quote}


\subsubsection{Notification delivery}

Register for receiving notifications, and log events which trigger
notification delivery. This checks the whole notification mechanism.

\req Package \texttt{glite-lb-client} installed, valid user credentials, environment variables (namely \texttt{GLITE\_WMS\_NOTIF\_SERVER}) set to point to the \LB server.

\how
First register for notifications. Option \texttt{-O}\footnote{Supported since \LBver{2.0}. For older versions, you need to use option \texttt{-j} and give at least one JobID of a job that already exists!} allows you to register for notifications on all your jobs:
\begin{quote}
\texttt{glite-lb-notify new -O}
\end{quote}
This prints out a notification ID (\emph{NotifID}) and validity information. Continue by listening for notifications, using that ID:
\begin{quote}
\texttt{glite-lb-notify receive} \emph{NotifID}
\end{quote}
Then, using a different console, register at least one job and generate events. Make sure you use the same Identity used to register for notifications in the first place.
\begin{quote}
\texttt{glite-lb-running.sh -m} \emph{server\_name:port}
\end{quote}

\result
The listener (\texttt{glite-lb-notify}) should print out notifications (JobID, state and owner), showing progressive changes of job state as events arrive to the server. There will be multiple notifications showing the same state. That is normal since not all events result in a job state change. If you want to see notifications only for job state changes, use option \texttt{-c} on registration.

For more test scenarios, see notification-related sections in~\cite{lbug,lbtp}. Especially \cite{lbug} has a comprehensive set of examples using the \texttt{glite-lb-notify} command.
